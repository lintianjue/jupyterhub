{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives\n",
    "\n",
    "* Basic experience with Machine Learning libraries like scikit/sklearn\n",
    "* Know the difference between classification and regression\n",
    "* Perform basic classifications in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning: Classification\n",
    "\n",
    "* Introduce the idea of **classification**\n",
    "* Compare classification and regression models\n",
    "* Explain what types of problems can be solved using classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Vs. Classification\n",
    "\n",
    "So far, we've studied **regression** problems that allow us to make predictions of the form $y = x\\cdot \\theta$\n",
    "\n",
    "* That is, we've assumed **real-valued** (or numerical) outputs\n",
    "\n",
    "How can we predict **binary** or **categorical** variables?\n",
    "\n",
    "<img src=\"Datasets/Classification.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why classification\n",
    "\n",
    "Will I **purchase** this product? (yes or no)\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Datasets/Movie.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Will I **click on** this ad? (yes or no)\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Datasets/Ring.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "What animal appear in this image? (mandarin duck)\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Datasets/Duck.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept: Linear Classification\n",
    "\n",
    "We'll attempt to build **classfiers** that make decisions according to rules of the form\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Datasets/Linear_Classification.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "This is called **linear classification**, since we're still making decisions according to a linear function, $X_i \\cdot \\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "A modification of regression algorithms to handle classification problems. So\n",
    "\n",
    "**Question**: how to convert a real valued expression ($X_i \\cdot \\theta\\in\\mathbb{R}$) into a probability $(p_{\\theta}(y_i | X_i)\\in [0, 1])$\n",
    "\n",
    "**Answer**\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Datasets/Sigmoid.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training of Logistic Regression\n",
    "\n",
    "$X_i \\cdot \\theta$ should be maximized when $y_i$ is positive and minimized when $y_i$ is nagative. \n",
    "\n",
    "Or equivalently, we have:\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Datasets/Training_func.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "**How to optimize?**\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Datasets/Optimize_func.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "* Take logarithm\n",
    "* Compute gradient\n",
    "* Solve using gradient **ascent**\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Datasets/Derivative.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - Polish companies bankruptcy data\n",
    "\n",
    "\n",
    "* The dataset is about bankruptcy prediction of Polish companies.The bankrupt companies were analyzed in the period 2000-2012, while the still operating companies were evaluated from 2007 to 2013\n",
    "\n",
    "<img src=\"Datasets/bankrupt_data.jpg\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code: Reading the data\n",
    "\n",
    "* Data is in CSV format, but first contains a header that we need to skip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "z = zipfile.ZipFile(\"Datasets/data.zip\")\n",
    "f = z.open(\"5year.arff\", 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** \n",
    "\n",
    "Header ends and the \"real\" data begins after we see the \"@data\" tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not b'@data' in f.readline():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next** we read the CSV data. We skip rows with missing entries; convert all fields to floats; and convert the label to a bool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0.078518,\n",
       " 0.20546,\n",
       " 0.10393,\n",
       " 2.7939,\n",
       " 77.784,\n",
       " 0.36515,\n",
       " 0.093388,\n",
       " 3.8672,\n",
       " 1.2322,\n",
       " 0.79454,\n",
       " 0.093388,\n",
       " 1.6119,\n",
       " 0.25844,\n",
       " 0.093388,\n",
       " 735.12,\n",
       " 0.49652,\n",
       " 4.8672,\n",
       " 0.093388,\n",
       " 0.23659,\n",
       " 32.076,\n",
       " 0.99207,\n",
       " 0.075428,\n",
       " 0.19892,\n",
       " 0.43626,\n",
       " 0.79454,\n",
       " 0.42414,\n",
       " 2.3545,\n",
       " 0.12401,\n",
       " 5.0933,\n",
       " 0.51863,\n",
       " 0.23659,\n",
       " 66.013,\n",
       " 5.5292,\n",
       " 0.36712,\n",
       " 0.075428,\n",
       " 0.41595,\n",
       " 0.86215,\n",
       " 0.94206,\n",
       " 0.19109,\n",
       " 0.045408,\n",
       " 0.080363,\n",
       " 0.19109,\n",
       " 147.25,\n",
       " 115.17,\n",
       " 2.2635,\n",
       " 2.1951,\n",
       " 39.524,\n",
       " 0.066803,\n",
       " 0.16924,\n",
       " 0.78786,\n",
       " 0.057938,\n",
       " 0.18086,\n",
       " 0.948,\n",
       " 1.124,\n",
       " 12885.0,\n",
       " 0.18842,\n",
       " 0.098822,\n",
       " 0.81158,\n",
       " 0.18566,\n",
       " 11.379,\n",
       " 3.1692,\n",
       " 53.575,\n",
       " 6.8129,\n",
       " 0.47096,\n",
       " False]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "for line in f:\n",
    "    if b'?' in line:\n",
    "        continue\n",
    "    line = line.split(b',')\n",
    "    values = [1] + [float(x) for x in line]\n",
    "    values[-1] = values[-1] > 0  # convert to bool\n",
    "    dataset.append(values)\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3028"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of **positive** samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x[-1] for x in dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next we extract our features (X) and labels (y), much as we would do for a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [values[:-1] for values in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [values[-1] for values in dataset]   # True/False labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: The ```sklearn``` library\n",
    "\n",
    "The ```sklearn``` library contains a number of different regression and classification models.\n",
    "\n",
    "* ```linear_model.LinearRegression()``` - linear regression\n",
    "* ```linear_model.LogisticRegression()``` - logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code: Fitting the logistic regression model\n",
    "\n",
    "* First we import the library and create an instance of the model, before fitting it to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21410\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(solver='liblinear')\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Note** that this function doesn't produce any output, rather it just update the class instance to store the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code: Making predictions\n",
    "\n",
    "* Make predictions from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check whether they match the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctPredictions = predictions == y\n",
    "correctPredictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* And compute the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666446499339498"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(correctPredictions) / len(correctPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Vs. Testing\n",
    "\n",
    "We achieved fairly high accuracy using a simple classifier \"off the shelf\"\n",
    "\n",
    "* But note that we're evaluating our classifer on the same data that was used to train it\n",
    "* How can we be sure that our classifier will work well on **unseen data**?\n",
    "* This is something we'll cover in the next course, when we look at **training, testing, and validation**\n",
    "\n",
    "If we **evaluate** a system on the same data used to **train** the system, we may overestimate its performance. Really, we want to know how well a method is likely to work on **unseen data**.\n",
    "\n",
    "To estimate how well a system is likely to perform on new data, we can split our dataset into two components:\n",
    "\n",
    "* A **training set** to train the machine learning model\n",
    "* A **test set** used to estimate the performance on new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code: Training and testing\n",
    "\n",
    "First we read the dataset, exactly as we did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Datasets/data/5year.arff\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not '@data' in f.readline():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0.088238,\n",
       " 0.55472,\n",
       " 0.01134,\n",
       " 1.0205,\n",
       " -66.52,\n",
       " 0.34204,\n",
       " 0.10949,\n",
       " 0.57752,\n",
       " 1.0881,\n",
       " 0.32036,\n",
       " 0.10949,\n",
       " 0.1976,\n",
       " 0.096885,\n",
       " 0.10949,\n",
       " 1475.2,\n",
       " 0.24742,\n",
       " 1.8027,\n",
       " 0.10949,\n",
       " 0.077287,\n",
       " 50.199,\n",
       " 1.1574,\n",
       " 0.13523,\n",
       " 0.062287,\n",
       " 0.41949,\n",
       " 0.32036,\n",
       " 0.20912,\n",
       " 1.0387,\n",
       " 0.026093,\n",
       " 6.1267,\n",
       " 0.37788,\n",
       " 0.077287,\n",
       " 155.33,\n",
       " 2.3498,\n",
       " 0.24377,\n",
       " 0.13523,\n",
       " 1.4493,\n",
       " 571.37,\n",
       " 0.32101,\n",
       " 0.095457,\n",
       " 0.12879,\n",
       " 0.11189,\n",
       " 0.095457,\n",
       " 127.3,\n",
       " 77.096,\n",
       " 0.45289,\n",
       " 0.66883,\n",
       " 54.621,\n",
       " 0.10746,\n",
       " 0.075859,\n",
       " 1.0193,\n",
       " 0.55407,\n",
       " 0.42557,\n",
       " 0.73717,\n",
       " 0.73866,\n",
       " 15182.0,\n",
       " 0.080955,\n",
       " 0.27543,\n",
       " 0.91905,\n",
       " 0.002024,\n",
       " 7.2711,\n",
       " 4.7343,\n",
       " 142.76,\n",
       " 2.5568,\n",
       " 3.2597,\n",
       " False]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for line in f:\n",
    "    if '?' in line:\n",
    "        continue\n",
    "    line = line.split(',')\n",
    "    values = [1] + [float(x) for x in line]\n",
    "    values[-1] = values[-1] > 0  # convert to bool\n",
    "    dataset.append(values)\n",
    "    \n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do differently is to **shuffle** the data:\n",
    "\n",
    "* We do this beacause we want the training and test set to be **random samples** of the data - if we didn't use random samples, different subsets of the data could have distinct characteristics that could cause the model to under- (or over) perform on one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [values[:-1] for values in dataset]\n",
    "y = [values[-1] for values in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we **split** the data into a **train** and a **test** portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X)\n",
    "\n",
    "X_train = X[:N//2]   # double-slash for “floor” division (rounds down to nearest whole number)\n",
    "X_test = X[N//2:]\n",
    "y_train = y[:N//2]\n",
    "y_test = y[N//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 1515, 1516)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train our model as before, but we use **only the training data and labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21410\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.LogisticRegression(solver='liblinear')\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can compute the accuracy of the model, but this time we do so seperately for the training and test portions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionTrain = model.predict(X_train)\n",
    "predictionTest = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctPredictionTrain = predictionTrain == y_train\n",
    "correctPredictionTest = predictionTest == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696369636963696"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(correctPredictionTrain) / len(correctPredictionTrain)   # Training Accuracy|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571240105540897"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(correctPredictionTest) / len(correctPredictionTest)    # Test Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latter quantity measures **how well the model is likely to perform on any data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of concepts\n",
    "\n",
    "* Simply training on a dataset doesn't give us a sense of how a model will **generalize to new data**\n",
    "* This generalization ability can be estimated using a test set\n",
    "* Training and test sets should be **non-overlapping, random** splits of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
